{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f830740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
    "from torchvision.models import resnet50, vit_b_16, vit_b_32\n",
    "# from tqdm.autonotebook import tqdm\n",
    "from copy import deepcopy\n",
    "# from cka import CKACalculator\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.rcParams['figure.figsize'] = (7, 7)\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# get the root project folder (one level up from the notebook)\n",
    "project_root = os.path.abspath(\"..\")\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from CNN import CNN\n",
    "from VisionTransormer import VisionTransformer\n",
    "\n",
    "# config \n",
    "import yaml\n",
    "\n",
    "config = yaml.safe_load(open('../config.yaml'))\n",
    "cnn_config = config['cnn']\n",
    "vt_config = config['vision_transformer']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a070445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() else\n",
    "    'mps' if torch.backends.mps.is_available() else\n",
    "    'cpu'\n",
    ")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf8e3514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = Compose([\n",
    "    Resize(224),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.485, 0.456, 0.406),\n",
    "              std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(root='../data', train=True, download=True, transform=transform)\n",
    "test_dataset  = CIFAR10(root='../data', train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = config['batch_size']\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "len(train_dataset), len(test_dataset)\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "\n",
    "train_percent = 0.002\n",
    "test_percent = 0.002\n",
    "\n",
    "# compute subset sizes\n",
    "train_size = int(len(train_dataset) * train_percent)\n",
    "test_size = int(len(test_dataset) * test_percent)\n",
    "\n",
    "# create random subset indices\n",
    "train_indices = np.random.choice(len(train_dataset), train_size, replace=False)\n",
    "test_indices = np.random.choice(len(test_dataset), test_size, replace=False)\n",
    "\n",
    "# create subsets\n",
    "training_data_small = Subset(train_dataset, train_indices)\n",
    "test_data_small = Subset(test_dataset, test_indices)\n",
    "\n",
    "# new loaders (keeping same batch size)\n",
    "train_loader = DataLoader(training_data_small, batch_size=config['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_data_small, batch_size=config['batch_size'], shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e97758c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/markgardner/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Identity()\n",
      "  (layer4): Identity()\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n",
      "Total number of parameters (excluding final linear layer): 683072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markgardner/miniconda3/envs/a4_vae/lib/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attempted to use an uninitialized parameter in <method 'numel' of 'torch._C.TensorBase' objects>. This error happens when you are using a `LazyModule` or explicitly manipulating `torch.nn.parameter.UninitializedParameter` objects. When using LazyModules Call `forward` with a dummy batch to initialize the parameters before calling torch functions",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# quick sanity check later:\u001b[39;00m\n\u001b[32m      5\u001b[39m model = CNN(cnn_config, device)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mcount_trainable_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mcount_trainable_params\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcount_trainable_params\u001b[39m(model):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcount_trainable_params\u001b[39m(model):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model.parameters() \u001b[38;5;28;01mif\u001b[39;00m p.requires_grad)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/a4_vae/lib/python3.11/site-packages/torch/nn/parameter.py:158\u001b[39m, in \u001b[36mUninitializedTensorMixin.__torch_function__\u001b[39m\u001b[34m(cls, func, types, args, kwargs)\u001b[39m\n\u001b[32m    156\u001b[39m         kwargs = {}\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().__torch_function__(func, types, args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    159\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAttempted to use an uninitialized parameter in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    160\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mThis error happens when you are using a `LazyModule` or \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    161\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mexplicitly manipulating `torch.nn.parameter.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    162\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mobjects. When using LazyModules Call `forward` with a dummy batch \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    163\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mto initialize the parameters before calling torch functions\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Attempted to use an uninitialized parameter in <method 'numel' of 'torch._C.TensorBase' objects>. This error happens when you are using a `LazyModule` or explicitly manipulating `torch.nn.parameter.UninitializedParameter` objects. When using LazyModules Call `forward` with a dummy batch to initialize the parameters before calling torch functions"
     ]
    }
   ],
   "source": [
    "def count_trainable_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# quick sanity check later:\n",
    "model = CNN(cnn_config, device)\n",
    "count_trainable_params(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ad77b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cnn(num_layers_to_drop: int):\n",
    "    cfg = dict(cnn_config)           # shallow copy\n",
    "    cfg['num_layers_to_drop'] = num_layers_to_drop\n",
    "    return CNN(cfg, device)\n",
    "\n",
    "def make_vit(num_encoder_layers_to_drop: int):\n",
    "    cfg = dict(vt_config)\n",
    "    cfg['num_encoder_layers_to_drop'] = num_encoder_layers_to_drop\n",
    "    return VisionTransformer(cfg, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d371e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 9 (2449710923.py, line 14)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mreturn history\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m expected an indented block after 'for' statement on line 9\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "def run_training(model, num_epochs, train_loader, test_loader):\n",
    "    # history = {\n",
    "    #     \"epoch\": [],\n",
    "    #     \"test_accuracy\": [],\n",
    "    #     \"test_loss\": [],\n",
    "    #     \"epoch_time\": [],\n",
    "    # }\n",
    "    history = {\n",
    "        \"epoch\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_accuracy\": [],\n",
    "        \"epoch_time\": [],\n",
    "    }\n",
    "\n",
    "\n",
    "    # for epoch in range(num_epochs):\n",
    "    #     start_time = time.time()\n",
    "\n",
    "    #     # train for one epoch\n",
    "    #     model.train(train_loader)\n",
    "    #     # evaluate on test\n",
    "    #     test_ret = model.test(test_loader)\n",
    "    #     # append results into history\n",
    "    #     history.append(test_ret)\n",
    "\n",
    "    # return history\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, batch in enumerate(training_loader):\n",
    "            loss = model.training_step(batch)\n",
    "            if batch_idx % config['print_batch_frequency'] == 0:\n",
    "                print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            test_result = model.test_step(batch)\n",
    "            test_loss += test_result[0]\n",
    "            correct += test_result[1]\n",
    "        test_loss /= len(test_loader)\n",
    "        correct /= len(test_data)\n",
    "        print(f\"Test Error for Epoch {epoch}: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    save_weights = config['save_weights_path']\n",
    "    if save_weights != '':\n",
    "        torch.save(model.state_dict(), save_weights)\n",
    "        print(\"Weights saved to {save_weights}\")\n",
    "\n",
    "#########################\n",
    "#########################\n",
    "#########################\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # TRAIN LOOP\n",
    "        total_train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch_loss = model.training_step(batch)\n",
    "            total_train_loss += batch_loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # TEST LOOP\n",
    "        total_test_loss = 0\n",
    "        total_correct = 0\n",
    "        for batch in test_loader:\n",
    "            test_loss, correct = model.test_step(batch)\n",
    "            total_test_loss += test_loss\n",
    "            total_correct += correct\n",
    "\n",
    "        avg_test_loss = total_test_loss / len(test_loader)\n",
    "        accuracy = total_correct / len(test_dataset)\n",
    "\n",
    "        # STORE HISTORY\n",
    "        history[\"epoch\"].append(epoch)\n",
    "        history[\"train_loss\"].append(avg_train_loss)\n",
    "        history[\"test_loss\"].append(avg_test_loss)\n",
    "        history[\"test_accuracy\"].append(accuracy)\n",
    "        history[\"epoch_time\"].append(time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f6be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "def run_training(model, num_epochs, train_loader, test_loader):\n",
    "\n",
    "    history = {\n",
    "        \"epoch\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_accuracy\": [],\n",
    "        \"epoch_time\": [],\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            loss = model.training_step(batch)\n",
    "            if batch_idx % config['print_batch_frequency'] == 0:\n",
    "                print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            test_result = model.test_step(batch)\n",
    "            test_loss += test_result[0]\n",
    "            correct += test_result[1]\n",
    "        test_loss /= len(test_loader)\n",
    "        correct /= len(test_data)\n",
    "        print(f\"Test Error for Epoch {epoch}: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    save_weights = config['save_weights_path']\n",
    "    if save_weights != '':\n",
    "        torch.save(model.state_dict(), save_weights)\n",
    "        print(\"Weights saved to {save_weights}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2878a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time \n",
    "\n",
    "def run_training(model, num_epochs, training_loader, test_loader, test_data, print_freq):\n",
    "\n",
    "    history = {\n",
    "        \"epoch\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_accuracy\": [],\n",
    "        \"epoch_time\": [],\n",
    "    }\n",
    "    # start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # ---- TRAIN EPOCH ----\n",
    "        train_loss_running = 0\n",
    "        for batch_idx, batch in enumerate(training_loader):\n",
    "            loss = model.training_step(batch)\n",
    "            train_loss_running += loss.item()\n",
    "\n",
    "            if batch_idx % print_freq == 0:\n",
    "                print(f\"[Epoch {epoch}] Batch {batch_idx} Loss: {loss.item():.4f}\")\n",
    "\n",
    "        avg_train_loss = train_loss_running / len(training_loader)\n",
    "\n",
    "        # ---- TEST EPOCH ----\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            test_l, corr = model.test_step(batch)\n",
    "            test_loss += test_l\n",
    "            correct += corr\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        accuracy = correct / len(test_data)\n",
    "\n",
    "        print(f\"Epoch {epoch}: Test Acc: {accuracy*100:.2f}%, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "        # ---- SAVE TO HISTORY ----\n",
    "        history[\"train_loss_per_epoch\"].append(avg_train_loss)\n",
    "        history[\"test_loss_per_epoch\"].append(test_loss)\n",
    "        history[\"test_accuracy_per_epoch\"].append(accuracy)\n",
    "    end = time.time()\n",
    "    total_time = end - start\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe4299da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_training(model, num_epochs, train_loader, test_loader, print_freq):\n",
    "    history = {\n",
    "        \"epoch\": [],\n",
    "        \"test_accuracy\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"total_time\": None,\n",
    "    }\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # ---- train loop (same as main.py) ----\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            loss = model.training_step(batch)\n",
    "            if batch_idx % print_freq == 0:\n",
    "                print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # ---- test loop (same as main.py, but we compute total manually) ----\n",
    "        test_loss = 0.0\n",
    "        correct = 0.0\n",
    "        total = 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            batch_loss, batch_correct = model.test_step(batch)\n",
    "            test_loss += batch_loss\n",
    "            correct += batch_correct\n",
    "            # batch[0] are the images\n",
    "            total += batch[0].size(0)\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        print(\n",
    "            f\"Test Error for Epoch {epoch}: \"\n",
    "            f\"Accuracy: {100 * accuracy:>0.1f}%, Avg loss: {test_loss:>8f}\\n\"\n",
    "        )\n",
    "\n",
    "        # ---- log history ----\n",
    "        history[\"epoch\"].append(epoch)\n",
    "        history[\"test_accuracy\"].append(float(accuracy))\n",
    "        history[\"test_loss\"].append(float(test_loss))\n",
    "\n",
    "    history[\"total_time\"] = time.time() - start_time\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b29aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n",
      "Total number of parameters (excluding final linear layer): 11176512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markgardner/miniconda3/envs/a4_vae/lib/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, Loss: 2.6519\n",
      "Test Error for Epoch 0: Accuracy: 20.0%, Avg loss: 3.809594\n",
      "\n",
      "Epoch 1, Batch 0, Loss: 3.7837\n",
      "Test Error for Epoch 1: Accuracy: 35.0%, Avg loss: 2.559745\n",
      "\n",
      "Epoch 2, Batch 0, Loss: 2.2152\n",
      "Test Error for Epoch 2: Accuracy: 25.0%, Avg loss: 2.035981\n",
      "\n",
      "Epoch 3, Batch 0, Loss: 1.2523\n",
      "Test Error for Epoch 3: Accuracy: 40.0%, Avg loss: 2.103549\n",
      "\n",
      "Epoch 4, Batch 0, Loss: 1.4942\n",
      "Test Error for Epoch 4: Accuracy: 40.0%, Avg loss: 1.836549\n",
      "\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Identity()\n",
      "  (layer4): Identity()\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n",
      "Total number of parameters (excluding final linear layer): 683072\n",
      "Epoch 0, Batch 0, Loss: 2.2665\n",
      "Test Error for Epoch 0: Accuracy: 15.0%, Avg loss: 2.260747\n",
      "\n",
      "Epoch 1, Batch 0, Loss: 2.2365\n",
      "Test Error for Epoch 1: Accuracy: 15.0%, Avg loss: 2.233810\n",
      "\n",
      "Epoch 2, Batch 0, Loss: 2.2229\n",
      "Test Error for Epoch 2: Accuracy: 10.0%, Avg loss: 2.222963\n",
      "\n",
      "Epoch 3, Batch 0, Loss: 2.2481\n",
      "Test Error for Epoch 3: Accuracy: 10.0%, Avg loss: 2.212201\n",
      "\n",
      "Epoch 4, Batch 0, Loss: 2.1770\n",
      "Test Error for Epoch 4: Accuracy: 15.0%, Avg loss: 2.202781\n",
      "\n",
      "VisionTransformer(\n",
      "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (encoder_layer_0): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_1): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_2): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_3): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_4): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_5): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_6): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_7): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_8): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_9): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_10): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_11): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (heads): Sequential(\n",
      "    (head): Identity()\n",
      "  )\n",
      ")\n",
      "Total number of parameters (excluding final linear layer): 85798656\n",
      "Epoch 0, Batch 0, Loss: 2.4348\n",
      "Test Error for Epoch 0: Accuracy: 5.0%, Avg loss: 2.484179\n",
      "\n",
      "Epoch 1, Batch 0, Loss: 2.4309\n",
      "Test Error for Epoch 1: Accuracy: 5.0%, Avg loss: 2.480984\n",
      "\n",
      "Epoch 2, Batch 0, Loss: 2.4309\n",
      "Test Error for Epoch 2: Accuracy: 5.0%, Avg loss: 2.477848\n",
      "\n",
      "Epoch 3, Batch 0, Loss: 2.4164\n",
      "Test Error for Epoch 3: Accuracy: 5.0%, Avg loss: 2.474672\n",
      "\n",
      "Epoch 4, Batch 0, Loss: 2.4718\n",
      "Test Error for Epoch 4: Accuracy: 5.0%, Avg loss: 2.471541\n",
      "\n",
      "VisionTransformer(\n",
      "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (encoder_layer_0): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_1): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_2): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_3): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (heads): Sequential(\n",
      "    (head): Identity()\n",
      "  )\n",
      ")\n",
      "Total number of parameters (excluding final linear layer): 29095680\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "num_epochs = config['num_epochs']\n",
    "print_freq = config['print_batch_frequency']\n",
    "\n",
    "# cnn_drop_list = [0, 1, 2]\n",
    "# vit_drop_list = [0, 4, 8]\n",
    "cnn_drop_list = [0, 2]\n",
    "vit_drop_list = [0, 8]\n",
    "\n",
    "results = []\n",
    "\n",
    "for num_drop in cnn_drop_list:\n",
    "    model = make_cnn(num_drop)\n",
    "\n",
    "    # initialize LazyLinear\n",
    "    dummy = next(iter(train_loader))[0].to(device)\n",
    "    with torch.no_grad():\n",
    "        _ = model(dummy)\n",
    "\n",
    "    n_params = count_trainable_params(model)\n",
    "    start_time = time.time()\n",
    "    history = run_training(model, num_epochs, train_loader, test_loader, print_freq)\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    results.append({\n",
    "        \"model\": \"cnn\",\n",
    "        \"layers_dropped\": num_drop,\n",
    "        \"params\": n_params,\n",
    "        \"history\": history,\n",
    "        \"run_time\": total_time\n",
    "    })\n",
    "\n",
    "for num_drop in vit_drop_list:\n",
    "    model = make_vit(num_drop)\n",
    "\n",
    "    dummy = next(iter(train_loader))[0].to(device)\n",
    "    with torch.no_grad():\n",
    "        _ = model(dummy)\n",
    "\n",
    "    n_params = count_trainable_params(model)\n",
    "    start_time = time.time()\n",
    "\n",
    "    history = run_training(model, num_epochs, train_loader, test_loader, print_freq)\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    results.append({\n",
    "        \"model\": \"vit\",\n",
    "        \"layers_dropped\": num_drop,\n",
    "        \"params\": n_params,\n",
    "        \"history\": history,\n",
    "        \"run_time\": total_time\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10751e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'cnn',\n",
       "  'layers_dropped': 0,\n",
       "  'params': 5130,\n",
       "  'history': {'epoch': [0, 1, 2, 3, 4],\n",
       "   'test_accuracy': [0.3, 0.2, 0.5, 0.35, 0.4],\n",
       "   'test_loss': [2.746870517730713,\n",
       "    3.0941123962402344,\n",
       "    2.067286252975464,\n",
       "    2.0940909385681152,\n",
       "    1.7339544296264648],\n",
       "   'total_time': 20.036497116088867}},\n",
       " {'model': 'cnn',\n",
       "  'layers_dropped': 2,\n",
       "  'params': 1290,\n",
       "  'history': {'epoch': [0, 1, 2, 3, 4],\n",
       "   'test_accuracy': [0.25, 0.2, 0.25, 0.2, 0.15],\n",
       "   'test_loss': [2.2805933952331543,\n",
       "    2.2670156955718994,\n",
       "    2.253814220428467,\n",
       "    2.229841709136963,\n",
       "    2.199183940887451],\n",
       "   'total_time': 14.324692964553833}},\n",
       " {'model': 'vit',\n",
       "  'layers_dropped': 0,\n",
       "  'params': 7690,\n",
       "  'history': {'epoch': [0, 1, 2, 3, 4],\n",
       "   'test_accuracy': [0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "   'test_loss': [2.3359689712524414,\n",
       "    2.3329410552978516,\n",
       "    2.3299031257629395,\n",
       "    2.3268628120422363,\n",
       "    2.3238558769226074],\n",
       "   'total_time': 135.3274688720703}},\n",
       " {'model': 'vit',\n",
       "  'layers_dropped': 8,\n",
       "  'params': 7690,\n",
       "  'history': {'epoch': [0, 1, 2, 3, 4],\n",
       "   'test_accuracy': [0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "   'test_loss': [2.3472249507904053,\n",
       "    2.3462319374084473,\n",
       "    2.345313787460327,\n",
       "    2.3443517684936523,\n",
       "    2.3433499336242676],\n",
       "   'total_time': 44.769124031066895}}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ddf521a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n",
      "Total number of parameters (excluding final linear layer): 11176512\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "run_training() missing 2 required positional arguments: 'test_data' and 'print_freq'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m     n_params = count_trainable_params(model)\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# n_params = count_trainable_params(model)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     history = \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     results.append({\n\u001b[32m     19\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcnn\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     20\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlayers_dropped\u001b[39m\u001b[33m\"\u001b[39m: num_drop,\n\u001b[32m     21\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: n_params,\n\u001b[32m     22\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhistory\u001b[39m\u001b[33m\"\u001b[39m: history,\n\u001b[32m     23\u001b[39m     })\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m num_drop \u001b[38;5;129;01min\u001b[39;00m vit_drop_list:\n",
      "\u001b[31mTypeError\u001b[39m: run_training() missing 2 required positional arguments: 'test_data' and 'print_freq'"
     ]
    }
   ],
   "source": [
    "num_epochs = config['num_epochs']\n",
    "\n",
    "cnn_drop_list = [0, 1, 2]   #  you can adjust\n",
    "vit_drop_list = [0, 4, 8]   #  not symmetric; thats okay\n",
    "\n",
    "results = []\n",
    "\n",
    "for num_drop in cnn_drop_list:\n",
    "    model = make_cnn(num_drop)\n",
    "    #  initialize LazyLinear by running one fake batch through the model\n",
    "    dummy = next(iter(train_loader))[0].to(device)  # just the images\n",
    "    with torch.no_grad():\n",
    "        _ = model(dummy)\n",
    "\n",
    "    n_params = count_trainable_params(model)\n",
    "    # n_params = count_trainable_params(model)\n",
    "    history = run_training(model, num_epochs, train_loader, test_loader)\n",
    "    results.append({\n",
    "        \"model\": \"cnn\",\n",
    "        \"layers_dropped\": num_drop,\n",
    "        \"params\": n_params,\n",
    "        \"history\": history,\n",
    "    })\n",
    "\n",
    "for num_drop in vit_drop_list:\n",
    "    model = make_vit(num_drop)\n",
    "        #  initialize LazyLinear by running one fake batch through the model\n",
    "    dummy = next(iter(train_loader))[0].to(device)  # just the images\n",
    "    with torch.no_grad():\n",
    "        _ = model(dummy)\n",
    "\n",
    "    n_params = count_trainable_params(model)\n",
    "    n_params = count_trainable_params(model)\n",
    "    history = run_training(model, num_epochs, train_loader, test_loader)\n",
    "    results.append({\n",
    "        \"model\": \"vit\",\n",
    "        \"layers_dropped\": num_drop,\n",
    "        \"params\": n_params,\n",
    "        \"history\": history,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd938422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a4_vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
